{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import gensim\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"Amazon_reviews_6T.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
    "    return text\n",
    "    \n",
    "data['body'] = data['body'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[data['Class'].notnull()].body\n",
    "y = data[data['Class'].notnull()].Class\n",
    "#y = y.map({'Fingerprint': 1, 'Value for money': 2,'Sound Quality':3,'Battery life':4,'Not good':5,'Picture Quality':6})\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Classification Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sushbiswal\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "   Battery life       0.00      0.00      0.00         2\n",
      "    Fingerprint       0.00      0.00      0.00         2\n",
      "Picture Quality       0.00      0.00      0.00         1\n",
      "  Sound Quality       0.00      0.00      0.00         2\n",
      "Value for money       0.56      1.00      0.72         9\n",
      "\n",
      "      micro avg       0.56      0.56      0.56        16\n",
      "      macro avg       0.11      0.20      0.14        16\n",
      "   weighted avg       0.32      0.56      0.40        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sushbiswal\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "   Battery life       0.00      0.00      0.00         2\n",
      "    Fingerprint       0.67      1.00      0.80         2\n",
      "Picture Quality       1.00      1.00      1.00         1\n",
      "  Sound Quality       0.00      0.00      0.00         2\n",
      "Value for money       0.67      0.89      0.76         9\n",
      "\n",
      "      micro avg       0.69      0.69      0.69        16\n",
      "      macro avg       0.47      0.58      0.51        16\n",
      "   weighted avg       0.52      0.69      0.59        16\n",
      "\n",
      "accuracy 0.6875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
    "               ])\n",
    "sgd.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "y_pred = sgd.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(n_jobs=1, C=1e5)),\n",
    "               ])\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "   Battery life       0.00      0.00      0.00         2\n",
      "    Fingerprint       0.33      0.50      0.40         2\n",
      "Picture Quality       1.00      1.00      1.00         1\n",
      "  Sound Quality       0.00      0.00      0.00         2\n",
      "Value for money       0.64      0.78      0.70         9\n",
      "\n",
      "      micro avg       0.56      0.56      0.56        16\n",
      "      macro avg       0.39      0.46      0.42        16\n",
      "   weighted avg       0.46      0.56      0.51        16\n",
      "\n",
      "accuracy 0.5625\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n"
     ]
    }
   ],
   "source": [
    "v=0\n",
    "for i in data[data['Class'].isnull()].index:\n",
    "    print(i)\n",
    "     \n",
    "    data.at[i, 'Class'] = logreg.predict(data[data['Class'].isnull()].body)[v]\n",
    "v=v+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"Final_predictedClasses.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn import utils\n",
    "import gensim\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_sentences(corpus, label_type):\n",
    "    \"\"\"\n",
    "    Gensim's Doc2Vec implementation requires each document/paragraph to have a label associated with it.\n",
    "    We do this by using the TaggedDocument method. The format will be \"TRAIN_i\" or \"TEST_i\" where \"i\" is\n",
    "    a dummy index of the post.\n",
    "    \"\"\"\n",
    "    labeled = []\n",
    "    for i, v in enumerate(corpus):\n",
    "        label = label_type + '_' + str(i)\n",
    "        labeled.append(TaggedDocument(v.split(), [label]))\n",
    "    return labeled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.3)\n",
    "X_train = label_sentences(X_train, 'Train')\n",
    "X_test = label_sentences(X_test, 'Test')\n",
    "all_data = X_train + X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 46/46 [00:00<00:00, 46025.28it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 46/46 [00:00<00:00, 91700.56it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 46/46 [00:00<00:00, 45904.83it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 46/46 [00:00<00:00, 22944.22it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 46/46 [00:00<00:00, 22876.21it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 46/46 [00:00<00:00, 45926.68it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 46/46 [00:00<00:00, 22946.95it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 46/46 [00:00<00:00, 45882.99it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 46/46 [00:00<00:00, 22941.50it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 46/46 [00:00<00:00, 91787.81it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 46/46 [00:00<00:00, 45882.99it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 46/46 [00:00<00:00, 45893.91it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 46/46 [00:00<00:00, 15306.46it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 46/46 [00:00<?, ?it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 46/46 [00:00<?, ?it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 46/46 [00:00<00:00, 45850.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 46/46 [00:00<?, ?it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 46/46 [00:00<00:00, 22832.90it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 46/46 [00:00<00:00, 45893.91it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 46/46 [00:00<00:00, 45893.91it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 46/46 [00:00<00:00, 45959.50it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 46/46 [00:00<00:00, 45882.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 46/46 [00:00<?, ?it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 46/46 [00:00<00:00, 45429.24it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 46/46 [00:00<00:00, 22936.04it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 46/46 [00:00<00:00, 45719.90it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 46/46 [00:00<00:00, 23070.43it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 46/46 [00:00<00:00, 45893.91it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 46/46 [00:00<00:00, 45676.61it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 46/46 [00:00<00:00, 45893.91it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 46/46 [00:00<00:00, 22941.50it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, min_count=1, alpha=0.065, min_alpha=0.065)\n",
    "model_dbow.build_vocab([x for x in tqdm(all_data)])\n",
    "\n",
    "for epoch in range(30):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(all_data)]), total_examples=len(all_data), epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(model, corpus_size, vectors_size, vectors_type):\n",
    "    \"\"\"\n",
    "    Get vectors from trained doc2vec model\n",
    "    :param doc2vec_model: Trained Doc2Vec model\n",
    "    :param corpus_size: Size of the data\n",
    "    :param vectors_size: Size of the embedding vectors\n",
    "    :param vectors_type: Training or Testing vectors\n",
    "    :return: list of vectors\n",
    "    \"\"\"\n",
    "    vectors = np.zeros((corpus_size, vectors_size))\n",
    "    for i in range(0, corpus_size):\n",
    "        prefix = vectors_type + '_' + str(i)\n",
    "        vectors[i] = model.docvecs[prefix]\n",
    "    return vectors\n",
    "    \n",
    "train_vectors_dbow = get_vectors(model_dbow, len(X_train), 300, 'Train')\n",
    "test_vectors_dbow = get_vectors(model_dbow, len(X_test), 300, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sushbiswal\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\sushbiswal\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\sushbiswal\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg.fit(train_vectors_dbow, y_train)\n",
    "logreg = logreg.fit(train_vectors_dbow, y_train)\n",
    "y_pred = logreg.predict(test_vectors_dbow)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sushbiswal\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\sushbiswal\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.50      0.50      0.50         8\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.29      0.29      0.29        14\n",
      "   macro avg       0.08      0.08      0.08        14\n",
      "weighted avg       0.29      0.29      0.29        14\n",
      "\n",
      "accuracy 0.2857142857142857\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
